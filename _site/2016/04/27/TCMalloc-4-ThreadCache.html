<!DOCTYPE html>
<html lang="zh-CN">
    <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>TCMalloc源码学习-4-ThreadCache</title>
  <meta name="description" content="这一篇讲一讲上层的ThreadCache，第一篇已经说过，每个线程都有自己的缓存，线程间的小内存申请和释放不需要全局锁抢锁，提高了分配效率，并且ThreadCache还有比较好的内存归还策略，尽可能的做到线程间的平衡，下面就来详细说一说">

  <link rel="canonical" href="https://kernelmaker.github.io/2016/04/27/TCMalloc-4-ThreadCache.html">

  <link rel="stylesheet" href="/assets/css/bootstrap.min.css">
  <!-- <link rel="stylesheet" href="/assets/css/icard_resume.css"> -->
  <link rel="stylesheet" href="/assets/css/font-awesome.min.css">
  <link rel="stylesheet" href="/assets/css/blog.css" >
  <link rel="stylesheet" href="/assets/css/syntax.css">

  <link rel="icon" type="image/png" href="/assets/img/avatar.jpeg">

  <!-- Google fonts -->
  <link rel='stylesheet' href='//fonts.googleapis.com/css?family=Open+Sans:300' type='text/css'>
  <link rel='stylesheet' href='//fonts.googleapis.com/css?family=Source+Sans+Pro' type='text/css'>

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
  <script src="assets/js/html5shiv.min.js"></script>
  <script src="assets/js/respond.min.js"></script>
  <![endif]-->

</head>

    <body>
        <header class="bloghead">
    <dev class="authorheader">
        <a href="/">
            <img alt="My Avatar" src="/assets/img/avatar.jpeg"/>
        </a>
        <dev class="blogtitle">
            <h1><a href="/">KernelMaker</a></h1>
            <h5> 墨鱼丸是只猫 </h5>
        </dev>
    </dev>

    <nav class="menu" role="nav">
        <ul>
            <li><a href="/">Home</a></li>
            <li>|</li>
            <li><a href="/menu.html">Menu</a></li>
            <li>|</li>
            <li><a target="_blank" href="https://github.com/kernelmaker">Github</a></li>
            <li>|</li>
            <li><a target="_blank" href="/about.html"> About Me</a></li>
        </ul>
    </nav>
</header>


        <main class="blogmain">
            <header>
                <h1 class="article-title">TCMalloc源码学习-4-ThreadCache</h1>
                <p class="article-time">
                    2016年04月27日 星期三,  发表于 <span>北京</span>
                </p>
                <p class="article-hint">
                    如果您对本文有任何的建议或者疑问, 可以在
                    <a href="https://github.com/kernelmaker/kernelmaker.github.io/issues" target="_blank">这里给我提 Issues</a>, 谢谢! :)
                </p>
            </header>
            <p>这一篇讲一讲上层的ThreadCache，第一篇已经说过，每个线程都有自己的缓存，线程间的小内存申请和释放不需要全局锁抢锁，提高了分配效率，并且ThreadCache还有比较好的内存归还策略，尽可能的做到线程间的平衡，下面就来详细说一说</p>

<h2 id="section">线程局部缓存</h2>

<p>怎么做到的呢，那就是pthread_key_create，来看定义：</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">NAME</span>
       <span class="n">pthread_key_create</span> <span class="o">-</span> <span class="kr">thread</span><span class="o">-</span><span class="n">specific</span> <span class="n">data</span> <span class="n">key</span> <span class="n">creation</span>

<span class="n">SYNOPSIS</span>
       <span class="cp">#include &lt;pthread.h&gt;
</span>
       <span class="kt">int</span> <span class="n">pthread_key_create</span><span class="p">(</span><span class="n">pthread_key_t</span> <span class="o">*</span><span class="n">key</span><span class="p">,</span> <span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">destructor</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="p">));</span>


<span class="n">DESCRIPTION</span>
       <span class="n">The</span> <span class="n">pthread_key_create</span><span class="p">()</span> <span class="n">function</span> <span class="n">shall</span> <span class="n">create</span> <span class="n">a</span> <span class="kr">thread</span><span class="o">-</span><span class="n">specific</span> <span class="n">data</span> <span class="n">key</span> <span class="n">visible</span> <span class="n">to</span> <span class="n">all</span> <span class="n">threads</span> <span class="n">in</span> <span class="n">the</span> <span class="n">process</span><span class="p">.</span> <span class="n">Key</span> <span class="n">values</span> <span class="n">provided</span> <span class="n">by</span> <span class="n">pthread_key_create</span><span class="p">()</span> <span class="n">are</span> <span class="n">opaque</span> <span class="n">objects</span> <span class="n">used</span>  <span class="n">to</span>  <span class="n">locate</span>  <span class="kr">thread</span><span class="o">-</span><span class="n">spe</span><span class="o">-</span>
       <span class="n">cific</span>  <span class="n">data</span><span class="p">.</span>  <span class="n">Although</span> <span class="n">the</span> <span class="n">same</span> <span class="n">key</span> <span class="n">value</span> <span class="n">may</span> <span class="n">be</span> <span class="n">used</span> <span class="n">by</span> <span class="n">different</span> <span class="n">threads</span><span class="p">,</span> <span class="n">the</span> <span class="n">values</span> <span class="n">bound</span> <span class="n">to</span> <span class="n">the</span> <span class="n">key</span> <span class="n">by</span> <span class="n">pthread_setspecific</span><span class="p">()</span> <span class="n">are</span> <span class="n">maintained</span> <span class="n">on</span> <span class="n">a</span> <span class="n">per</span><span class="o">-</span><span class="kr">thread</span> <span class="n">basis</span> <span class="n">and</span> <span class="n">persist</span> <span class="k">for</span> <span class="n">the</span> <span class="n">life</span> <span class="n">of</span> <span class="n">the</span> <span class="n">calling</span>
       <span class="kr">thread</span><span class="p">.</span>

       <span class="n">Upon</span> <span class="n">key</span> <span class="n">creation</span><span class="p">,</span> <span class="n">the</span> <span class="n">value</span> <span class="nb">NULL</span> <span class="n">shall</span> <span class="n">be</span> <span class="n">associated</span> <span class="n">with</span> <span class="n">the</span> <span class="k">new</span> <span class="n">key</span> <span class="n">in</span> <span class="n">all</span> <span class="n">active</span> <span class="n">threads</span><span class="p">.</span> <span class="n">Upon</span> <span class="kr">thread</span> <span class="n">creation</span><span class="p">,</span> <span class="n">the</span> <span class="n">value</span> <span class="nb">NULL</span> <span class="n">shall</span> <span class="n">be</span> <span class="n">associated</span> <span class="n">with</span> <span class="n">all</span> <span class="n">defined</span> <span class="n">keys</span> <span class="n">in</span> <span class="n">the</span> <span class="k">new</span> <span class="kr">thread</span><span class="p">.</span>

       <span class="n">An</span> <span class="n">optional</span> <span class="n">destructor</span> <span class="n">function</span> <span class="n">may</span> <span class="n">be</span> <span class="n">associated</span> <span class="n">with</span> <span class="n">each</span> <span class="n">key</span> <span class="n">value</span><span class="p">.</span>  <span class="n">At</span> <span class="kr">thread</span> <span class="n">exit</span><span class="p">,</span> <span class="k">if</span> <span class="n">a</span> <span class="n">key</span> <span class="n">value</span> <span class="n">has</span> <span class="n">a</span> <span class="n">non</span><span class="o">-</span><span class="nb">NULL</span> <span class="n">destructor</span> <span class="n">pointer</span><span class="p">,</span> <span class="n">and</span> <span class="n">the</span> <span class="kr">thread</span> <span class="n">has</span> <span class="n">a</span> <span class="n">non</span><span class="o">-</span><span class="nb">NULL</span> <span class="n">value</span> <span class="n">associated</span> <span class="n">with</span> <span class="n">that</span>  <span class="n">key</span><span class="p">,</span>  <span class="n">the</span>
       <span class="n">value</span> <span class="n">of</span> <span class="n">the</span> <span class="n">key</span> <span class="n">is</span> <span class="n">set</span> <span class="n">to</span> <span class="nb">NULL</span><span class="p">,</span> <span class="n">and</span> <span class="n">then</span> <span class="n">the</span> <span class="n">function</span> <span class="n">pointed</span> <span class="n">to</span> <span class="n">is</span> <span class="n">called</span> <span class="n">with</span> <span class="n">the</span> <span class="n">previously</span> <span class="n">associated</span> <span class="n">value</span> <span class="n">as</span> <span class="n">its</span> <span class="n">sole</span> <span class="n">argument</span><span class="p">.</span> <span class="n">The</span> <span class="n">order</span> <span class="n">of</span> <span class="n">destructor</span> <span class="n">calls</span> <span class="n">is</span> <span class="n">unspecified</span> <span class="k">if</span> <span class="n">more</span> <span class="n">than</span> <span class="n">one</span> <span class="n">destruc</span><span class="o">-</span>
       <span class="n">tor</span> <span class="n">exists</span> <span class="k">for</span> <span class="n">a</span> <span class="kr">thread</span> <span class="n">when</span> <span class="n">it</span> <span class="n">exits</span><span class="p">.</span>

       <span class="n">If</span><span class="p">,</span> <span class="n">after</span> <span class="n">all</span> <span class="n">the</span> <span class="n">destructors</span> <span class="n">have</span> <span class="n">been</span> <span class="n">called</span> <span class="k">for</span> <span class="n">all</span> <span class="n">non</span><span class="o">-</span><span class="nb">NULL</span> <span class="n">values</span> <span class="n">with</span> <span class="n">associated</span> <span class="n">destructors</span><span class="p">,</span> <span class="n">there</span> <span class="n">are</span> <span class="n">still</span> <span class="n">some</span> <span class="n">non</span><span class="o">-</span><span class="nb">NULL</span> <span class="n">values</span> <span class="n">with</span> <span class="n">associated</span> <span class="n">destructors</span><span class="p">,</span> <span class="n">then</span>  <span class="n">the</span>  <span class="n">process</span>  <span class="n">is</span>  <span class="n">repeated</span><span class="p">.</span>   <span class="n">If</span><span class="p">,</span>
       <span class="n">after</span>  <span class="n">at</span>  <span class="n">least</span>  <span class="p">{</span><span class="n">PTHREAD_DESTRUCTOR_ITERATIONS</span><span class="p">}</span>  <span class="n">iterations</span> <span class="n">of</span> <span class="n">destructor</span> <span class="n">calls</span> <span class="k">for</span> <span class="n">outstanding</span> <span class="n">non</span><span class="o">-</span><span class="nb">NULL</span> <span class="n">values</span><span class="p">,</span> <span class="n">there</span> <span class="n">are</span> <span class="n">still</span> <span class="n">some</span> <span class="n">non</span><span class="o">-</span><span class="nb">NULL</span> <span class="n">values</span> <span class="n">with</span> <span class="n">associated</span> <span class="n">destructors</span><span class="p">,</span> <span class="n">implementations</span> <span class="n">may</span> <span class="n">stop</span>
       <span class="n">calling</span> <span class="n">destructors</span><span class="p">,</span> <span class="n">or</span> <span class="n">they</span> <span class="n">may</span> <span class="k">continue</span> <span class="n">calling</span> <span class="n">destructors</span> <span class="n">until</span> <span class="n">no</span> <span class="n">non</span><span class="o">-</span><span class="nb">NULL</span> <span class="n">values</span> <span class="n">with</span> <span class="n">associated</span> <span class="n">destructors</span> <span class="n">exist</span><span class="p">,</span> <span class="n">even</span> <span class="n">though</span> <span class="k">this</span> <span class="n">might</span> <span class="n">result</span> <span class="n">in</span> <span class="n">an</span> <span class="n">infinite</span> <span class="n">loop</span><span class="p">.</span>
</code></pre>
</div>
<p>来看看ThreadCreate如何用的，在初始化函数InitTSD里，通过<code class="highlighter-rouge">pthread_key_create(&amp;heap_key_, DestroyThreadCache)</code>来定义一个<code class="highlighter-rouge">pthread_key_t</code>变量<code class="highlighter-rouge">heap_key_</code>，这样，后来每个线程在自己初始化的时候，只要通过<code class="highlighter-rouge">pthread_setspecific(heap_key_, heap)</code>就可以定义自己的局部缓存heap，然后通过<code class="highlighter-rouge">pthread_getspecific(heap_key_)</code>便可以拿到自己的局部缓存了，并且在线程退出的时候，会回调DestroyThreadCache来释放自己的heap，好了原理就是这个了，还有一个是如果内核支持TLS，就用TLS，这里还没有具体看</p>

<h2 id="section-1">结构</h2>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ThreadCache</span> <span class="p">{</span>
 <span class="k">public</span><span class="o">:</span>
  <span class="c1">// All ThreadCache objects are kept in a linked list (for stats collection)
</span>  <span class="n">ThreadCache</span><span class="o">*</span> <span class="n">next_</span><span class="p">;</span>
  <span class="n">ThreadCache</span><span class="o">*</span> <span class="n">prev_</span><span class="p">;</span>
  
  <span class="n">FreeList</span>      <span class="n">list_</span><span class="p">[</span><span class="n">kNumClasses</span><span class="p">];</span>     <span class="c1">// Array indexed by size-class
</span>  
  <span class="c1">// Allocate an object of the given size and class. The size given
</span>  <span class="c1">// must be the same as the size of the class in the size map.
</span>  <span class="kt">void</span><span class="o">*</span> <span class="n">Allocate</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">cl</span><span class="p">);</span>
  <span class="kt">void</span> <span class="n">Deallocate</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">ptr</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">size_class</span><span class="p">);</span>
  
  <span class="k">static</span> <span class="n">pthread_key_t</span> <span class="n">heap_key_</span><span class="p">;</span>
  <span class="k">static</span> <span class="n">ThreadCache</span><span class="o">*</span> <span class="n">thread_heaps_</span><span class="p">;</span>
  <span class="k">static</span> <span class="kt">int</span> <span class="n">thread_heap_count_</span><span class="p">;</span>
  
  <span class="k">static</span> <span class="kt">void</span>         <span class="n">InitTSD</span><span class="p">();</span>
  <span class="k">static</span> <span class="n">ThreadCache</span><span class="o">*</span> <span class="n">GetThreadHeap</span><span class="p">();</span>
  <span class="k">static</span> <span class="n">ThreadCache</span><span class="o">*</span> <span class="n">GetCache</span><span class="p">();</span>
  <span class="k">static</span> <span class="n">ThreadCache</span><span class="o">*</span> <span class="n">GetCacheIfPresent</span><span class="p">();</span>
  <span class="k">static</span> <span class="n">ThreadCache</span><span class="o">*</span> <span class="n">CreateCacheIfNecessary</span><span class="p">();</span>
  <span class="k">static</span> <span class="n">ThreadCache</span><span class="o">*</span> <span class="n">NewHeap</span><span class="p">(</span><span class="n">pthread_t</span> <span class="n">tid</span><span class="p">);</span>

  <span class="c1">// Use only as pthread thread-specific destructor function.
</span>  <span class="k">static</span> <span class="kt">void</span> <span class="n">DestroyThreadCache</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">ptr</span><span class="p">);</span>

  <span class="k">static</span> <span class="kt">void</span> <span class="n">DeleteCache</span><span class="p">(</span><span class="n">ThreadCache</span><span class="o">*</span> <span class="n">heap</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">extern</span> <span class="n">PageHeapAllocator</span><span class="o">&lt;</span><span class="n">ThreadCache</span><span class="o">&gt;</span> <span class="n">threadcache_allocator</span><span class="p">;</span>
</code></pre>
</div>
<p>这个就是ThreadCache的主要成员，可以看到他有很多static的变量和函数，包括上一节说到的InitTSD，每个ThreadCache对象管理每个线程的缓存，并且所有的ThreadCache串成链表中，由next和prev来记录先后顺序，可能要问了：为什么用链表，线程A为什么要知道线程B对应的ThreadCache？因为为了内存分配的平衡，需要线程之间做动态调整，比如线程A会把线程B的缓存上限调小来迫使线程B释放一部分缓存。最后，list_便是每个线程的局部缓存，同样是有86个，ThreadCache对象和Span对象的创建一样，都是通过PageHeapAllocator来创建</p>

<p>用户调用malloc，判读如果是小内存，它会首先执行GetCache来获取所属线程自己的ThreadCache对象，来看下实现：</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kr">inline</span> <span class="n">ThreadCache</span><span class="o">*</span> <span class="n">ThreadCache</span><span class="o">::</span><span class="n">GetCache</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">ThreadCache</span><span class="o">*</span> <span class="n">ptr</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
  <span class="c1">//如果是首次调用，则执行InitModule来初始化一堆static变量，包括CentralFreeList和PageHeap
</span>  <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">tsd_inited_</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">InitModule</span><span class="p">();</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
  <span class="c1">//否则，获取所属线程的局部缓存heap，也就是通过pthread_getspecific来获取
</span>    <span class="n">ptr</span> <span class="o">=</span> <span class="n">GetThreadHeap</span><span class="p">();</span>
  <span class="p">}</span>
  <span class="c1">//第一次肯定是还没有创建局部heap，所以上一步返回的ptr是NULL，这里创建一个heap，并通过pthread_setspecific绑定局部heap
</span>  <span class="k">if</span> <span class="p">(</span><span class="n">ptr</span> <span class="o">==</span> <span class="nb">NULL</span><span class="p">)</span> <span class="n">ptr</span> <span class="o">=</span> <span class="n">CreateCacheIfNecessary</span><span class="p">();</span>
  <span class="k">return</span> <span class="n">ptr</span><span class="p">;</span>
<span class="p">}</span>
</code></pre>
</div>

<p>获取到ThreadCache对象之后，便可以通过Allocate和Deallocate来申请和释放小内存了，来分别看下实现：</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c1">//调用者do_malloc会根据用户传的usersize来判断，如果小于256k，则通过查表找到usersize对应的classsize索引cl和对应的实际分配size，传给Allocate
</span><span class="kr">inline</span> <span class="kt">void</span><span class="o">*</span> <span class="n">ThreadCache</span><span class="o">::</span><span class="n">Allocate</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">cl</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">ASSERT</span><span class="p">(</span><span class="n">size</span> <span class="o">&lt;=</span> <span class="n">kMaxSize</span><span class="p">);</span>
  <span class="n">ASSERT</span><span class="p">(</span><span class="n">size</span> <span class="o">==</span> <span class="n">Static</span><span class="o">::</span><span class="n">sizemap</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">ByteSizeForClass</span><span class="p">(</span><span class="n">cl</span><span class="p">));</span>

  <span class="c1">//直接在对应的缓存list里面找
</span>  <span class="n">FreeList</span><span class="o">*</span> <span class="n">list</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">list_</span><span class="p">[</span><span class="n">cl</span><span class="p">];</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">list</span><span class="o">-&gt;</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
    <span class="c1">//如果没有，从CentralFreeList申请，并插回list_
</span>    <span class="k">return</span> <span class="n">FetchFromCentralCache</span><span class="p">(</span><span class="n">cl</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="n">size_</span> <span class="o">-=</span> <span class="n">size</span><span class="p">;</span>
  <span class="k">return</span> <span class="n">list</span><span class="o">-&gt;</span><span class="n">Pop</span><span class="p">();</span>
<span class="p">}</span>

<span class="c1">// Remove some objects of class "cl" from central cache and add to thread heap.
// On success, return the first object for immediate use; otherwise return NULL.
</span><span class="kt">void</span><span class="o">*</span> <span class="n">ThreadCache</span><span class="o">::</span><span class="n">FetchFromCentralCache</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">cl</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">byte_size</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">FreeList</span><span class="o">*</span> <span class="n">list</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">list_</span><span class="p">[</span><span class="n">cl</span><span class="p">];</span>
  <span class="n">ASSERT</span><span class="p">(</span><span class="n">list</span><span class="o">-&gt;</span><span class="n">empty</span><span class="p">());</span>
  <span class="c1">//cl对应的每次向CentralFreeList申请object个数
</span>  <span class="k">const</span> <span class="kt">int</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">Static</span><span class="o">::</span><span class="n">sizemap</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">num_objects_to_move</span><span class="p">(</span><span class="n">cl</span><span class="p">);</span>
  <span class="c1">//每次移动的object数不超过max_length
</span>  <span class="k">const</span> <span class="kt">int</span> <span class="n">num_to_move</span> <span class="o">=</span> <span class="n">min</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">list</span><span class="o">-&gt;</span><span class="n">max_length</span><span class="p">(),</span> <span class="n">batch_size</span><span class="p">);</span>
  <span class="kt">void</span> <span class="o">*</span><span class="n">start</span><span class="p">,</span> <span class="o">*</span><span class="n">end</span><span class="p">;</span>
  <span class="c1">//从CentralFreeList中取回一批object
</span>  <span class="kt">int</span> <span class="n">fetch_count</span> <span class="o">=</span> <span class="n">Static</span><span class="o">::</span><span class="n">central_cache</span><span class="p">()[</span><span class="n">cl</span><span class="p">].</span><span class="n">RemoveRange</span><span class="p">(</span>
      <span class="o">&amp;</span><span class="n">start</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">end</span><span class="p">,</span> <span class="n">num_to_move</span><span class="p">);</span>

  <span class="n">ASSERT</span><span class="p">((</span><span class="n">start</span> <span class="o">==</span> <span class="nb">NULL</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">fetch_count</span> <span class="o">==</span> <span class="mi">0</span><span class="p">));</span>
  <span class="k">if</span> <span class="p">(</span><span class="o">--</span><span class="n">fetch_count</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">size_</span> <span class="o">+=</span> <span class="n">byte_size</span> <span class="o">*</span> <span class="n">fetch_count</span><span class="p">;</span>
    <span class="c1">//插入缓存list_
</span>    <span class="n">list</span><span class="o">-&gt;</span><span class="n">PushRange</span><span class="p">(</span><span class="n">fetch_count</span><span class="p">,</span> <span class="n">SLL_Next</span><span class="p">(</span><span class="n">start</span><span class="p">),</span> <span class="n">end</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="c1">// Increase max length slowly up to batch_size.  After that,
</span>  <span class="c1">// increase by batch_size in one shot so that the length is a
</span>  <span class="c1">// multiple of batch_size.
</span>  <span class="c1">//这里是对每次从CentralFreeList中拿多少个object进行动态调整，第一篇说到有一个数组记录着每个cl每次从CentralFreeList中拿多少，但并不是这样，max_length初始值是1，第一次拿1个，max_length加1，第二次拿两个，max_length加2，直到某次拿的数目，也就是max_length &gt;= batch_size，这以后就每次拿batch_size个，max_length每次加batch_size，类似于慢启动的方式，这里是一个优化
</span>  <span class="k">if</span> <span class="p">(</span><span class="n">list</span><span class="o">-&gt;</span><span class="n">max_length</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">batch_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">list</span><span class="o">-&gt;</span><span class="n">set_max_length</span><span class="p">(</span><span class="n">list</span><span class="o">-&gt;</span><span class="n">max_length</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="c1">// Don't let the list get too long.  In 32 bit builds, the length
</span>    <span class="c1">// is represented by a 16 bit int, so we need to watch out for
</span>    <span class="c1">// integer overflow.
</span>    <span class="kt">int</span> <span class="n">new_length</span> <span class="o">=</span> <span class="n">min</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">list</span><span class="o">-&gt;</span><span class="n">max_length</span><span class="p">()</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">,</span>
                              <span class="n">kMaxDynamicFreeListLength</span><span class="p">);</span>
    <span class="c1">// The list's max_length must always be a multiple of batch_size,
</span>    <span class="c1">// and kMaxDynamicFreeListLength is not necessarily a multiple
</span>    <span class="c1">// of batch_size.
</span>    <span class="n">new_length</span> <span class="o">-=</span> <span class="n">new_length</span> <span class="o">%</span> <span class="n">batch_size</span><span class="p">;</span>
    <span class="n">ASSERT</span><span class="p">(</span><span class="n">new_length</span> <span class="o">%</span> <span class="n">batch_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">);</span>
    <span class="n">list</span><span class="o">-&gt;</span><span class="n">set_max_length</span><span class="p">(</span><span class="n">new_length</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="k">return</span> <span class="n">start</span><span class="p">;</span>
<span class="p">}</span>
</code></pre>
</div>

<p>再来看一下Deallocate</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kr">inline</span> <span class="kt">void</span> <span class="n">ThreadCache</span><span class="o">::</span><span class="n">Deallocate</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">ptr</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">cl</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">FreeList</span><span class="o">*</span> <span class="n">list</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">list_</span><span class="p">[</span><span class="n">cl</span><span class="p">];</span>
  <span class="n">size_</span> <span class="o">+=</span> <span class="n">Static</span><span class="o">::</span><span class="n">sizemap</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">ByteSizeForClass</span><span class="p">(</span><span class="n">cl</span><span class="p">);</span>
  <span class="c1">//max_size和当前size的差值
</span>  <span class="kt">ssize_t</span> <span class="n">size_headroom</span> <span class="o">=</span> <span class="n">max_size_</span> <span class="o">-</span> <span class="n">size_</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span>

  <span class="c1">// This catches back-to-back frees of allocs in the same size
</span>  <span class="c1">// class. A more comprehensive (and expensive) test would be to walk
</span>  <span class="c1">// the entire freelist. But this might be enough to find some bugs.
</span>  <span class="n">ASSERT</span><span class="p">(</span><span class="n">ptr</span> <span class="o">!=</span> <span class="n">list</span><span class="o">-&gt;</span><span class="n">Next</span><span class="p">());</span>
  <span class="c1">//插入回list
</span>  <span class="n">list</span><span class="o">-&gt;</span><span class="n">Push</span><span class="p">(</span><span class="n">ptr</span><span class="p">);</span>
  <span class="c1">//max_length和当前list长度的差值
</span>  <span class="kt">ssize_t</span> <span class="n">list_headroom</span> <span class="o">=</span>
      <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">ssize_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">list</span><span class="o">-&gt;</span><span class="n">max_length</span><span class="p">())</span> <span class="o">-</span> <span class="n">list</span><span class="o">-&gt;</span><span class="n">length</span><span class="p">();</span>

  <span class="c1">// There are two relatively uncommon things that require further work.
</span>  <span class="c1">// In the common case we're done, and in that case we need a single branch
</span>  <span class="c1">// because of the bitwise-or trick that follows.
</span>  <span class="k">if</span> <span class="p">((</span><span class="n">list_headroom</span> <span class="o">|</span> <span class="n">size_headroom</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">//如果当前list的长度大于max_length，刚开始的时候是每次1，2，3，4...个从CentralFreeList中拿，max_length也每次增加同样的长度，如果此时list的长度大于max_length，也就是说已经过了慢启动的状态，list每次向CentralFreeList都申请batch_size个，这时有内存还回来，list过长，需要缩容
</span>    <span class="k">if</span> <span class="p">(</span><span class="n">list_headroom</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
      <span class="c1">//这里做了一些事情，下面具体看一下
</span>      <span class="n">ListTooLong</span><span class="p">(</span><span class="n">list</span><span class="p">,</span> <span class="n">cl</span><span class="p">);</span>
    <span class="p">}</span>
    	<span class="c1">//如果当前的缓存的size大于max_size，这回收内存
</span>    <span class="k">if</span> <span class="p">(</span><span class="n">size_</span> <span class="o">&gt;=</span> <span class="n">max_size_</span><span class="p">)</span> <span class="n">Scavenge</span><span class="p">();</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="n">ThreadCache</span><span class="o">::</span><span class="n">ListTooLong</span><span class="p">(</span><span class="n">FreeList</span><span class="o">*</span> <span class="n">list</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">cl</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">const</span> <span class="kt">int</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">Static</span><span class="o">::</span><span class="n">sizemap</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">num_objects_to_move</span><span class="p">(</span><span class="n">cl</span><span class="p">);</span>
  <span class="c1">//还batch_size个object给CentralFreeList
</span>  <span class="n">ReleaseToCentralCache</span><span class="p">(</span><span class="n">list</span><span class="p">,</span> <span class="n">cl</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">);</span>

  <span class="c1">// If the list is too long, we need to transfer some number of
</span>  <span class="c1">// objects to the central cache.  Ideally, we would transfer
</span>  <span class="c1">// num_objects_to_move, so the code below tries to make max_length
</span>  <span class="c1">// converge on num_objects_to_move.
</span>  <span class="c1">//感觉这里不会进来？？？需要再确认一下
</span>  <span class="k">if</span> <span class="p">(</span><span class="n">list</span><span class="o">-&gt;</span><span class="n">max_length</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">batch_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Slow start the max_length so we don't overreserve.
</span>    <span class="n">list</span><span class="o">-&gt;</span><span class="n">set_max_length</span><span class="p">(</span><span class="n">list</span><span class="o">-&gt;</span><span class="n">max_length</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">list</span><span class="o">-&gt;</span><span class="n">max_length</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">batch_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">//如果连还kMaxOverages次，每次max_length都大于batch_size，则将max_size减小，减小batch_size个
</span>    <span class="c1">// If we consistently go over max_length, shrink max_length.  If we don't
</span>    <span class="c1">// shrink it, some amount of memory will always stay in this freelist.
</span>    <span class="n">list</span><span class="o">-&gt;</span><span class="n">set_length_overages</span><span class="p">(</span><span class="n">list</span><span class="o">-&gt;</span><span class="n">length_overages</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">list</span><span class="o">-&gt;</span><span class="n">length_overages</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">kMaxOverages</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">ASSERT</span><span class="p">(</span><span class="n">list</span><span class="o">-&gt;</span><span class="n">max_length</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">batch_size</span><span class="p">);</span>
      <span class="n">list</span><span class="o">-&gt;</span><span class="n">set_max_length</span><span class="p">(</span><span class="n">list</span><span class="o">-&gt;</span><span class="n">max_length</span><span class="p">()</span> <span class="o">-</span> <span class="n">batch_size</span><span class="p">);</span>
      <span class="n">list</span><span class="o">-&gt;</span><span class="n">set_length_overages</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="c1">// Release idle memory to the central cache
</span><span class="kt">void</span> <span class="n">ThreadCache</span><span class="o">::</span><span class="n">Scavenge</span><span class="p">()</span> <span class="p">{</span>
  <span class="c1">// If the low-water mark for the free list is L, it means we would
</span>  <span class="c1">// not have had to allocate anything from the central cache even if
</span>  <span class="c1">// we had reduced the free list size by L.  We aim to get closer to
</span>  <span class="c1">// that situation by dropping L/2 nodes from the free list.  This
</span>  <span class="c1">// may not release much memory, but if so we will call scavenge again
</span>  <span class="c1">// pretty soon and the low-water marks will be high on that call.
</span>  <span class="c1">//int64 start = CycleClock::Now();
</span>  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">cl</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">cl</span> <span class="o">&lt;</span> <span class="n">kNumClasses</span><span class="p">;</span> <span class="n">cl</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">FreeList</span><span class="o">*</span> <span class="n">list</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">list_</span><span class="p">[</span><span class="n">cl</span><span class="p">];</span>
    <span class="k">const</span> <span class="kt">int</span> <span class="n">lowmark</span> <span class="o">=</span> <span class="n">list</span><span class="o">-&gt;</span><span class="n">lowwatermark</span><span class="p">();</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">lowmark</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    	<span class="c1">//lowatermark初始都为0，也就是说这个函数的第一次调用不会进到这里
</span>      <span class="k">const</span> <span class="kt">int</span> <span class="n">drop</span> <span class="o">=</span> <span class="p">(</span><span class="n">lowmark</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="o">?</span> <span class="n">lowmark</span><span class="o">/</span><span class="mi">2</span> <span class="o">:</span> <span class="mi">1</span><span class="p">;</span>
      <span class="c1">//每个list释放lowmark一般长度的缓存给CentralFreeList
</span>      <span class="n">ReleaseToCentralCache</span><span class="p">(</span><span class="n">list</span><span class="p">,</span> <span class="n">cl</span><span class="p">,</span> <span class="n">drop</span><span class="p">);</span>

      <span class="c1">// Shrink the max length if it isn't used.  Only shrink down to
</span>      <span class="c1">// batch_size -- if the thread was active enough to get the max_length
</span>      <span class="c1">// above batch_size, it will likely be that active again.  If
</span>      <span class="c1">// max_length shinks below batch_size, the thread will have to
</span>      <span class="c1">// go through the slow-start behavior again.  The slow-start is useful
</span>      <span class="c1">// mainly for threads that stay relatively idle for their entire
</span>      <span class="c1">// lifetime.
</span>      <span class="k">const</span> <span class="kt">int</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">Static</span><span class="o">::</span><span class="n">sizemap</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">num_objects_to_move</span><span class="p">(</span><span class="n">cl</span><span class="p">);</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">list</span><span class="o">-&gt;</span><span class="n">max_length</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">batch_size</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">//如果当前max_length大于batch_size，设置max_length为差值和batch_size的最小值
</span>        <span class="n">list</span><span class="o">-&gt;</span><span class="n">set_max_length</span><span class="p">(</span>
            <span class="n">max</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">list</span><span class="o">-&gt;</span><span class="n">max_length</span><span class="p">()</span> <span class="o">-</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">));</span>
      <span class="p">}</span>
    <span class="p">}</span>
    <span class="c1">//设置lowwatermark为当前list长度
</span>    <span class="n">list</span><span class="o">-&gt;</span><span class="n">clear_lowwatermark</span><span class="p">();</span>
  <span class="p">}</span>
  <span class="n">IncreaseCacheLimit</span><span class="p">();</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="n">ThreadCache</span><span class="o">::</span><span class="n">IncreaseCacheLimit</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">SpinLockHolder</span> <span class="n">h</span><span class="p">(</span><span class="n">Static</span><span class="o">::</span><span class="n">pageheap_lock</span><span class="p">());</span>
  <span class="n">IncreaseCacheLimitLocked</span><span class="p">();</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="n">ThreadCache</span><span class="o">::</span><span class="n">IncreaseCacheLimitLocked</span><span class="p">()</span> <span class="p">{</span>
  <span class="c1">//unclaimed初始值是32M，也就是说所有每个线程一共可以缓存32M(好像不是硬上限)，如果缓存空间还没用完，每次将max_size_增加kStealAmount即可
</span>  <span class="k">if</span> <span class="p">(</span><span class="n">unclaimed_cache_space_</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Possibly make unclaimed_cache_space_ negative.
</span>    <span class="n">unclaimed_cache_space_</span> <span class="o">-=</span> <span class="n">kStealAmount</span><span class="p">;</span>
    <span class="n">max_size_</span> <span class="o">+=</span> <span class="n">kStealAmount</span><span class="p">;</span>
    <span class="k">return</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="c1">// Don't hold pageheap_lock too long.  Try to steal from 10 other
</span>  <span class="c1">// threads before giving up.  The i &lt; 10 condition also prevents an
</span>  <span class="c1">// infinite loop in case none of the existing thread heaps are
</span>  <span class="c1">// suitable places to steal from.
</span>  <span class="c1">// 如果缓存空间已经用完，则需要从其他线程去偷一些，尝试偷10次，遍历其他线程的ThreadCache
</span>  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">;</span>
       <span class="o">++</span><span class="n">i</span><span class="p">,</span> <span class="n">next_memory_steal_</span> <span class="o">=</span> <span class="n">next_memory_steal_</span><span class="o">-&gt;</span><span class="n">next_</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Reached the end of the linked list.  Start at the beginning.
</span>    <span class="k">if</span> <span class="p">(</span><span class="n">next_memory_steal_</span> <span class="o">==</span> <span class="nb">NULL</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">ASSERT</span><span class="p">(</span><span class="n">thread_heaps_</span> <span class="o">!=</span> <span class="nb">NULL</span><span class="p">);</span>
      <span class="n">next_memory_steal_</span> <span class="o">=</span> <span class="n">thread_heaps_</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="c1">//其他线程的max_size_小于kMin，不偷
</span>    <span class="k">if</span> <span class="p">(</span><span class="n">next_memory_steal_</span> <span class="o">==</span> <span class="k">this</span> <span class="o">||</span>
        <span class="n">next_memory_steal_</span><span class="o">-&gt;</span><span class="n">max_size_</span> <span class="o">&lt;=</span> <span class="n">kMinThreadCacheSize</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">continue</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="c1">//偷：减少其他线程的max_size_ ，增加给自己，其他线程的max_size减少后，会在Deallocate最后触发Scavenge()，还一些给CentralFreeList
</span>    <span class="n">next_memory_steal_</span><span class="o">-&gt;</span><span class="n">max_size_</span> <span class="o">-=</span> <span class="n">kStealAmount</span><span class="p">;</span>
    <span class="n">max_size_</span> <span class="o">+=</span> <span class="n">kStealAmount</span><span class="p">;</span>

    <span class="n">next_memory_steal_</span> <span class="o">=</span> <span class="n">next_memory_steal_</span><span class="o">-&gt;</span><span class="n">next_</span><span class="p">;</span>
    <span class="k">return</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre>
</div>

<p>可以看到，真正Allocate和Deallocate不难，难的是Deallocate进行内存归还的策略，主要靠max_length和max_size来触发，并且max_size可以由其他线程来改，确保每个线程不会缓存太多，假设用户陆陆续续申请了加起来有100M的小内存，那么在陆陆续续释放超过32M的时候，由于当前已经缓存了32M，所以会触发Scavenge，还回去一些，这里有一个问题是，假如不是自己触发的，而是因为其他线程偷了一些，修改了本线程的max_size，这里是不是只要这个线程再不申请和归还内存，就不会进到判断是否触发scavenge的逻辑，也就是说线程缓存的内存一直不释放，当然，这个值不会太多，否则当初还的时候自己会触发scavenge的，这是自己的理解，不知道对不对</p>

<h2 id="section-2">总结</h2>
<p>ThreadCache应该是TCMalloc里比较复杂的部分了，复杂的不是实现，而是内存申请和归还的策略，感觉自己理解的还不够充分，先写这么多，以后有新的理解了再加，下篇讲讲用户接口，下篇见^^</p>

            <footer class="article-footer">
    <div class="authorimage">
        <img src="/assets/img/avatar.jpeg" alt="My Avatar" class="img-circle">
    </div>
    <section class="author">
        <h4><a href="/about.html">KernelMaker</a></h4>
        <a href="mailto:songzhao.asm@icloud.com">songzhao.asm@icloud.com</a>
    </section>
</footer>

        </main>

        <div class="footer-copyright">
    <div class="container-fluid">
        <div class="row-fluid">
            <div class="col-md-12">
                Copyright &copy; 2016 KernelMaker - All rights reserved.
            </div>
        </div>
    </div>
</div>
<script type="text/javascript" src="/assets/js/jquery.min.js"></script>
<script type="text/javascript" src="/assets/js/bootstrap.min.js"></script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-74743250-2', 'auto');
  ga('send', 'pageview');

</script>


    </body>

</html>
